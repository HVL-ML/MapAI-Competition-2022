{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade ipywidgets\r\n",
        "!pip install segmentation-models-pytorch\r\n",
        "!pip install kornia"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already up-to-date: ipywidgets in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (8.0.2)\nRequirement already satisfied, skipping upgrade: ipykernel>=4.5.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from ipywidgets) (6.8.0)\nRequirement already satisfied, skipping upgrade: traitlets>=4.3.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from ipywidgets) (5.3.0)\nRequirement already satisfied, skipping upgrade: widgetsnbextension~=4.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from ipywidgets) (4.0.3)\nRequirement already satisfied, skipping upgrade: ipython>=6.1.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from ipywidgets) (8.4.0)\nRequirement already satisfied, skipping upgrade: jupyterlab-widgets~=3.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from ipywidgets) (3.0.3)\nRequirement already satisfied, skipping upgrade: matplotlib-inline<0.2.0,>=0.1.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.3)\nRequirement already satisfied, skipping upgrade: debugpy<2.0,>=1.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.2)\nRequirement already satisfied, skipping upgrade: nest-asyncio in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.5)\nRequirement already satisfied, skipping upgrade: jupyter-client<8.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.12)\nRequirement already satisfied, skipping upgrade: tornado<7.0,>=4.2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.2)\nRequirement already satisfied, skipping upgrade: pygments>=2.4.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (2.12.0)\nRequirement already satisfied, skipping upgrade: setuptools>=18.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (49.6.0)\nRequirement already satisfied, skipping upgrade: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.28)\nRequirement already satisfied, skipping upgrade: pickleshare in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\nRequirement already satisfied, skipping upgrade: backcall in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\nRequirement already satisfied, skipping upgrade: jedi>=0.16 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.0)\nRequirement already satisfied, skipping upgrade: stack-data in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.3.0)\nRequirement already satisfied, skipping upgrade: decorator in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\nRequirement already satisfied, skipping upgrade: pexpect>4.3; sys_platform != \"win32\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\nRequirement already satisfied, skipping upgrade: jupyter-core>=4.6.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (4.11.1)\nRequirement already satisfied, skipping upgrade: pyzmq>=13 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (23.2.0)\nRequirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (2.8.2)\nRequirement already satisfied, skipping upgrade: wcwidth in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.5)\nRequirement already satisfied, skipping upgrade: parso<0.9.0,>=0.8.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\nRequirement already satisfied, skipping upgrade: asttokens in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.5)\nRequirement already satisfied, skipping upgrade: pure-eval in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\nRequirement already satisfied, skipping upgrade: executing in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.9.1)\nRequirement already satisfied, skipping upgrade: ptyprocess>=0.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from pexpect>4.3; sys_platform != \"win32\"->ipython>=6.1.0->ipywidgets) (0.7.0)\nRequirement already satisfied, skipping upgrade: six>=1.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from python-dateutil>=2.1->jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (1.16.0)\nRequirement already satisfied: segmentation-models-pytorch in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (0.3.1)\nRequirement already satisfied: tqdm in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from segmentation-models-pytorch) (4.64.0)\nRequirement already satisfied: pillow in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from segmentation-models-pytorch) (9.3.0)\nRequirement already satisfied: torchvision>=0.5.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from segmentation-models-pytorch) (0.9.1)\nRequirement already satisfied: pretrainedmodels==0.7.4 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from segmentation-models-pytorch) (0.7.4)\nRequirement already satisfied: timm==0.4.12 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from segmentation-models-pytorch) (0.4.12)\nRequirement already satisfied: efficientnet-pytorch==0.7.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from segmentation-models-pytorch) (0.7.1)\nRequirement already satisfied: torch==1.8.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (1.8.1)\nRequirement already satisfied: numpy in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (1.21.6)\nRequirement already satisfied: munch in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch) (2.5.0)\nRequirement already satisfied: typing-extensions in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from torch==1.8.1->torchvision>=0.5.0->segmentation-models-pytorch) (4.3.0)\nRequirement already satisfied: six in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from munch->pretrainedmodels==0.7.4->segmentation-models-pytorch) (1.16.0)\nCollecting kornia\n  Downloading kornia-0.6.8-py2.py3-none-any.whl (551 kB)\n\u001b[K     |████████████████████████████████| 551 kB 5.4 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: torch>=1.8.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from kornia) (1.8.1)\nRequirement already satisfied: packaging in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from kornia) (21.3)\nRequirement already satisfied: typing-extensions in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from torch>=1.8.1->kornia) (4.3.0)\nRequirement already satisfied: numpy in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from torch>=1.8.1->kornia) (1.21.6)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from packaging->kornia) (3.0.9)\nInstalling collected packages: kornia\nSuccessfully installed kornia-0.6.8\n"
        }
      ],
      "execution_count": 36,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": true
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\r\n",
        "%autoreload 2\r\n",
        "\r\n",
        "import os\r\n",
        "import sys\r\n",
        "sys.path.append(\".\")\r\n",
        "import numpy as np\r\n",
        "from yaml import load, dump, Loader, Dumper\r\n",
        "from tqdm import tqdm\r\n",
        "import torch\r\n",
        "import torchvision\r\n",
        "from tabulate import tabulate\r\n",
        "\r\n",
        "import argparse\r\n",
        "import time\r\n",
        "\r\n",
        "from competition_toolkit.dataloader import create_dataloader\r\n",
        "from utils import create_run_dir, store_model_weights, record_scores\r\n",
        "\r\n",
        "from competition_toolkit.eval_functions import calculate_score"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1670180833150
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "opts = {\r\n",
        "    'task': 2,\r\n",
        "    'data_ratio': 1,\r\n",
        "    'epochs': 20,\r\n",
        "    'device': 0,\r\n",
        "    'lr': 1e-3,\r\n",
        "    'imagesize': 512,\r\n",
        "    'rundir': 'runs',\r\n",
        "    \"task1\": {\r\n",
        "        \"batchsize\": 6,\r\n",
        "        'shuffle': True,\r\n",
        "    },\r\n",
        "    \"task2\": {\r\n",
        "        \"batchsize\": 4,\r\n",
        "        'shuffle': True,\r\n",
        "    }\r\n",
        "}"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1670180833293
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import segmentation_models_pytorch as smp\r\n",
        "from torch import nn\r\n",
        "\r\n",
        "# model = smp.Linknet(\r\n",
        "#         encoder_name=\"timm-resnest26d\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\r\n",
        "#         encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\r\n",
        "#         in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\r\n",
        "#         classes=2,                      # model output channels (number of classes in your dataset)\r\n",
        "#     )\r\n",
        "\r\n",
        "trained_task1_net = torch.load(\"task1_0.8838_augs_3losses.pt\")\r\n",
        "\r\n",
        "model = nn.Sequential(\r\n",
        "    nn.Conv2d(4, 8, 3, padding=1),\r\n",
        "    nn.ReLU(),\r\n",
        "    nn.Conv2d(8, 3, 3, padding=1),\r\n",
        "    trained_task1_net\r\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1670180989702
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations as A\r\n",
        "from albumentations.pytorch import ToTensorV2\r\n",
        "\r\n",
        "\r\n",
        "transforms = A.Compose(\r\n",
        "    [\r\n",
        "        A.RandomRotate90(p=0.5),\r\n",
        "        A.Flip(p=0.75),\r\n",
        "        A.GaussNoise(p=0.2),\r\n",
        "        ToTensorV2(),\r\n",
        "    ]\r\n",
        ")\r\n",
        "\r\n",
        "image_only_transforms = A.Compose(\r\n",
        "    [\r\n",
        "        A.HueSaturationValue(p=0.5),\r\n",
        "        A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.5),\r\n",
        "        # A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\r\n",
        "    ]\r\n",
        ")\r\n",
        "\r\n",
        "val_transforms = A.Compose(\r\n",
        "    [\r\n",
        "        ToTensorV2(),\r\n",
        "    ]\r\n",
        ")\r\n",
        "\r\n",
        "val_image_only_transforms = None"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1670180839480
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "from yaml import load, dump, Loader, Dumper\r\n",
        "from tqdm import tqdm\r\n",
        "import torch\r\n",
        "import torchvision\r\n",
        "from tabulate import tabulate\r\n",
        "\r\n",
        "import argparse\r\n",
        "import time\r\n",
        "\r\n",
        "from competition_toolkit.dataloader import create_dataloader\r\n",
        "from utils import create_run_dir, store_model_weights, record_scores\r\n",
        "\r\n",
        "from competition_toolkit.eval_functions import calculate_score\r\n",
        "\r\n",
        "from kornia.losses import DiceLoss\r\n",
        "from boundary_loss import BoundaryLoss\r\n",
        "\r\n",
        "\r\n",
        "def test(opts, dataloader, model, lossfn):\r\n",
        "    model.eval()\r\n",
        "\r\n",
        "    device = opts[\"device\"]\r\n",
        "\r\n",
        "    losstotal = np.zeros((len(dataloader)), dtype=float)\r\n",
        "    ioutotal = np.zeros((len(dataloader)), dtype=float)\r\n",
        "    bioutotal = np.zeros((len(dataloader)), dtype=float)\r\n",
        "    scoretotal = np.zeros((len(dataloader)), dtype=float)\r\n",
        "\r\n",
        "    for idx, batch in tqdm(enumerate(dataloader), leave=False, total=len(dataloader), desc=\"Test\"):\r\n",
        "        image, label, filename = batch\r\n",
        "        image = image.to(device).float()\r\n",
        "        label = label.to(device).long()\r\n",
        "\r\n",
        "        output = model(image)#[\"out\"]\r\n",
        "\r\n",
        "        loss = lossfn(output, label).item()\r\n",
        "\r\n",
        "        output = torch.argmax(torch.softmax(output, dim=1), dim=1)\r\n",
        "        if device != \"cpu\":\r\n",
        "            metrics = calculate_score(output.detach().cpu().numpy().astype(np.uint8),\r\n",
        "                                      label.detach().cpu().numpy().astype(np.uint8))\r\n",
        "        else:\r\n",
        "            metrics = calculate_score(output.detach().numpy().astype(np.uint8), label.detach().numpy().astype(np.uint8))\r\n",
        "\r\n",
        "        losstotal[idx] = loss\r\n",
        "        ioutotal[idx] = metrics[\"iou\"]\r\n",
        "        bioutotal[idx] = metrics[\"biou\"]\r\n",
        "        scoretotal[idx] = metrics[\"score\"]\r\n",
        "\r\n",
        "    loss = round(losstotal.mean(), 4)\r\n",
        "    iou = round(ioutotal.mean(), 4)\r\n",
        "    biou = round(bioutotal.mean(), 4)\r\n",
        "    score = round(scoretotal.mean(), 4)\r\n",
        "\r\n",
        "    return loss, iou, biou, score\r\n",
        "\r\n",
        "\r\n",
        "def train(model, opts, transforms, image_only_transforms, val_transforms, val_image_only_transforms):\r\n",
        "    device = opts[\"device\"]\r\n",
        "\r\n",
        "    # The current model should be swapped with a different one of your choice\r\n",
        "    # model = torchvision.models.segmentation.fcn_resnet50(pretrained=False, num_classes=opts[\"num_classes\"])\r\n",
        "\r\n",
        "    # if opts[\"task\"] == 2:\r\n",
        "    #     new_conv1 = torch.nn.Conv2d(4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\r\n",
        "    #     model.backbone.conv1 = new_conv1\r\n",
        "\r\n",
        "    model.to(device)\r\n",
        "    # model = model.float()\r\n",
        "\r\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=opts[\"lr\"])\r\n",
        "\r\n",
        "    lossfn = torch.nn.CrossEntropyLoss()\r\n",
        "    ce_loss = torch.nn.CrossEntropyLoss()\r\n",
        "    dice_loss = DiceLoss(eps=1e-6)\r\n",
        "    boundary_loss = BoundaryLoss()\r\n",
        "\r\n",
        "    epochs = opts[\"epochs\"]\r\n",
        "\r\n",
        "    trainloader = create_dataloader(opts, transforms, image_only_transforms, \"train\")\r\n",
        "    valloader = create_dataloader(opts, val_transforms, val_image_only_transforms, \"validation\")\r\n",
        "\r\n",
        "    bestscore = 0\r\n",
        "\r\n",
        "    for e in range(epochs):\r\n",
        "\r\n",
        "        model.train()\r\n",
        "\r\n",
        "        losstotal = np.zeros((len(trainloader)), dtype=float)\r\n",
        "        scoretotal = np.zeros((len(trainloader)), dtype=float)\r\n",
        "        ioutotal = np.zeros((len(trainloader)), dtype=float)\r\n",
        "        bioutotal = np.zeros((len(trainloader)), dtype=float)\r\n",
        "\r\n",
        "        stime = time.time()\r\n",
        "        \r\n",
        "        preview_loss = True\r\n",
        "        for idx, batch in tqdm(enumerate(trainloader), leave=True, total=len(trainloader), desc=\"Train\", position=0):\r\n",
        "        # for idx, batch in enumerate(trainloader):\r\n",
        "            image, label, filename = batch\r\n",
        "            image = image.float().to(device)\r\n",
        "            label = label.long().to(device).long()\r\n",
        "\r\n",
        "            output = model(image)#[\"out\"]\r\n",
        "            bl = boundary_loss(output, label) * 0.1\r\n",
        "            ce = ce_loss(output, label)\r\n",
        "            di = dice_loss(output, label)\r\n",
        "            loss = (bl + ce + di).mean()\r\n",
        "\r\n",
        "            if preview_loss:\r\n",
        "                print(e, \"| bl, ce, di losses:\", bl.item(), ce.item(), di.item())\r\n",
        "                preview_loss = False\r\n",
        "\r\n",
        "            optimizer.zero_grad()\r\n",
        "            loss.backward()\r\n",
        "            optimizer.step()\r\n",
        "\r\n",
        "            lossitem = loss.item()\r\n",
        "            output = torch.argmax(torch.softmax(output, dim=1), dim=1)\r\n",
        "            if device != \"cpu\":\r\n",
        "                trainmetrics = calculate_score(output.detach().cpu().numpy().astype(np.uint8),\r\n",
        "                                               label.detach().cpu().numpy().astype(np.uint8))\r\n",
        "            else:\r\n",
        "                trainmetrics = calculate_score(output.detach().numpy().astype(np.uint8),\r\n",
        "                                               label.detach().numpy().astype(np.uint8))\r\n",
        "\r\n",
        "            losstotal[idx] = lossitem\r\n",
        "            ioutotal[idx] = trainmetrics[\"iou\"]\r\n",
        "            bioutotal[idx] = trainmetrics[\"biou\"]\r\n",
        "            scoretotal[idx] = trainmetrics[\"score\"]\r\n",
        "\r\n",
        "        testloss, testiou, testbiou, testscore = test(opts, valloader, model, lossfn)\r\n",
        "        trainloss = round(losstotal.mean(), 4)\r\n",
        "        trainiou = round(ioutotal.mean(), 4)\r\n",
        "        trainbiou = round(bioutotal.mean(), 4)\r\n",
        "        trainscore = round(scoretotal.mean(), 4)\r\n",
        "\r\n",
        "        if testscore > bestscore:\r\n",
        "            bestscore = testscore\r\n",
        "            print(\"new best score:\", bestscore, \"- saving model weights\")\r\n",
        "            store_model_weights(opts, model, f\"best\", testscore, epoch=e)\r\n",
        "        else:\r\n",
        "            store_model_weights(opts, model, f\"last\", testscore, epoch=e)\r\n",
        "\r\n",
        "        print(\"\")\r\n",
        "        print(tabulate(\r\n",
        "            [[\"train\", trainloss, trainiou, trainbiou, trainscore], [\"test\", testloss, testiou, testbiou, testscore]],\r\n",
        "            headers=[\"Type\", \"Loss\", \"IoU\", \"BIoU\", \"Score\"]))\r\n",
        "\r\n",
        "        scoredict = {\r\n",
        "            \"epoch\": e,\r\n",
        "            \"trainloss\": trainloss,\r\n",
        "            \"testloss\": testloss,\r\n",
        "            \"trainiou\": trainiou,\r\n",
        "            \"testiou\": testiou,\r\n",
        "            \"trainbiou\": trainbiou,\r\n",
        "            \"testbiou\": testbiou,\r\n",
        "            \"trainscore\": trainscore,\r\n",
        "            \"testscore\": testscore\r\n",
        "        }\r\n",
        "\r\n",
        "        record_scores(opts, scoredict)"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1670181885414
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model.load_state_dict(torch.load(\"runs/best_task1_16_0.869100.pt\"))\r\n",
        "train(model, opts, transforms, image_only_transforms, val_transforms, val_image_only_transforms)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Reusing dataset mapai_training_data (/home/azureuser/.cache/huggingface/datasets/sjyhne___mapai_training_data/building_segmentation/1.0.0/b0b52f8c47ddbeae1962ab524cabb5fbed58d91cc70f9ac4c5981c071ad5f248)\nReusing dataset mapai_training_data (/home/azureuser/.cache/huggingface/datasets/sjyhne___mapai_training_data/building_segmentation/1.0.0/b0b52f8c47ddbeae1962ab524cabb5fbed58d91cc70f9ac4c5981c071ad5f248)\nTrain: 100%|██████████| 1750/1750 [47:17<00:00,  1.62s/it]\nTrain:  51%|█████▏    | 899/1750 [24:30<22:52,  1.61s/it]IOPub message rate exceeded.\nThe Jupyter server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n`--ServerApp.iopub_msg_rate_limit`.\n\nCurrent values:\nServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\nServerApp.rate_limit_window=3.0 (secs)\n\nTrain: 100%|██████████| 1750/1750 [44:18<00:00,  1.52s/it]\nTrain: 100%|██████████| 1750/1750 [45:10<00:00,  1.55s/it]\nTrain:  63%|██████▎   | 1110/1750 [27:10<15:34,  1.46s/it]IOPub message rate exceeded.\nThe Jupyter server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n`--ServerApp.iopub_msg_rate_limit`.\n\nCurrent values:\nServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\nServerApp.rate_limit_window=3.0 (secs)\n\nTrain: 100%|██████████| 1750/1750 [41:51<00:00,  1.44s/it]\nTrain:  44%|████▍     | 770/1750 [18:20<23:14,  1.42s/it]IOPub message rate exceeded.\nThe Jupyter server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n`--ServerApp.iopub_msg_rate_limit`.\n\nCurrent values:\nServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\nServerApp.rate_limit_window=3.0 (secs)\n\nTrain:  54%|█████▍    | 943/1750 [23:53<20:26,  1.52s/it]\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Using number of images in traindataset: 7000/7000\nUsing number of images in validationdataset: 1500/1500\n0 | bl, ce, di losses: 0.04499164596199989 0.07638144493103027 0.044584646821022034\nUsing number of images in traindataset: 7000/7000\nUsing number of images in validationdataset: 1500/1500\n0 | bl, ce, di losses: 0.09742705523967743 0.47766655683517456 0.219547301530838\nnew best score: 0.8881 - saving model weights\n\nType      Loss     IoU    BIoU    Score\n------  ------  ------  ------  -------\ntrain   0.219   0.8512  0.7202   0.7857\ntest    0.0583  0.9265  0.8496   0.8881\n1 | bl, ce, di losses: 0.03629662096500397 0.02051679790019989 0.010181158781051636\nnew best score: 0.8917 - saving model weights\n\nType      Loss     IoU    BIoU    Score\n------  ------  ------  ------  -------\ntrain   0.1811  0.893   0.7753   0.8341\ntest    0.0565  0.9295  0.8539   0.8917\n3 | bl, ce, di losses: 0.03529854118824005 0.11649422347545624 0.04541245102882385\nnew best score: 0.8953 - saving model weights\n\nType      Loss     IoU    BIoU    Score\n------  ------  ------  ------  -------\ntrain   0.1681  0.8999  0.7909   0.8454\ntest    0.0554  0.9324  0.8583   0.8953\n"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# model.load_state_dict(torch.load(\"runs/best_task1_16_0.869100.pt\"))\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransforms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_only_transforms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_transforms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_image_only_transforms\u001b[49m\u001b[43m)\u001b[49m\n",
            "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, opts, transforms, image_only_transforms, val_transforms, val_image_only_transforms)\u001b[0m\n\u001b[1;32m     97\u001b[0m stime \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     99\u001b[0m preview_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, batch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(trainloader), leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(trainloader), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain\u001b[39m\u001b[38;5;124m\"\u001b[39m, position\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# for idx, batch in enumerate(trainloader):\u001b[39;00m\n\u001b[1;32m    102\u001b[0m     image, label, filename \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m    103\u001b[0m     image \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(device)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/torch/utils/data/dataloader.py:517\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 517\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    520\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    521\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/torch/utils/data/dataloader.py:557\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    556\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 557\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    558\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    559\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:44\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 44\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:44\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 44\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/competition_toolkit/dataloader.py:157\u001b[0m, in \u001b[0;36mImageLabelAndLidarDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m imagefilepath\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m lidarfilepath\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimagefilename and labelfilename does not match; \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimagefilepath\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m != \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabelfilepath\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    155\u001b[0m filename \u001b[38;5;241m=\u001b[39m imagefilepath\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 157\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mload_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimagefilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopts\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimagesize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopts\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimagesize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m label \u001b[38;5;241m=\u001b[39m load_label(labelfilepath, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopts[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimagesize\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopts[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimagesize\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[1;32m    159\u001b[0m lidar \u001b[38;5;241m=\u001b[39m load_lidar(lidarfilepath, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopts[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimagesize\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopts[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimagesize\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/competition_toolkit/dataloader.py:31\u001b[0m, in \u001b[0;36mload_image\u001b[0;34m(imagepath, size)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_image\u001b[39m(imagepath: \u001b[38;5;28mstr\u001b[39m, size: \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m---> 31\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimagepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIMREAD_COLOR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m     image \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mcvtColor(image, cv\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[1;32m     33\u001b[0m     image \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mresize(image, size)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1670221514729
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lossfn = torch.nn.CrossEntropyLoss()\r\n",
        "\r\n",
        "epochs = opts[\"epochs\"]\r\n",
        "\r\n",
        "valloader = create_dataloader(opts, val_transforms, val_image_only_transforms, \"validation\")\r\n",
        "\r\n",
        "testloss, testiou, testbiou, testscore = test(opts, valloader, model, lossfn)\r\n",
        "testloss, testiou, testbiou, testscore"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1670167195363
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# store_model_weights(opts, model, f\"best\", testscore, epoch=\"\")\r\n",
        "# torch.save(model, \"task1_0.8838_augs_3losses.pt\")\r\n",
        "# torch.save(model, \"task2_0.9014_augs_3losses.pt\")"
      ],
      "outputs": [],
      "execution_count": 69,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1670171141867
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(\"runs/best_task2_10_0.901400.pt\"))\r\n",
        "model.to(opts['device'])"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 33,
          "data": {
            "text/plain": "Sequential(\n  (0): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (1): ReLU()\n  (2): Conv2d(8, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (3): Linknet(\n    (encoder): ResNestEncoder(\n      (conv1): Sequential(\n        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n        (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (5): ReLU(inplace=True)\n        (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n      (layer1): Sequential(\n        (0): ResNestBottleneck(\n          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act1): ReLU(inplace=True)\n          (conv2): SplitAttn(\n            (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n            (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act0): ReLU(inplace=True)\n            (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act1): ReLU(inplace=True)\n            (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n            (rsoftmax): RadixSoftmax()\n          )\n          (bn2): Identity()\n          (act2): Identity()\n          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act3): ReLU(inplace=True)\n          (downsample): Sequential(\n            (0): Identity()\n            (1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (1): ResNestBottleneck(\n          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act1): ReLU(inplace=True)\n          (conv2): SplitAttn(\n            (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n            (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act0): ReLU(inplace=True)\n            (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n            (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act1): ReLU(inplace=True)\n            (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n            (rsoftmax): RadixSoftmax()\n          )\n          (bn2): Identity()\n          (act2): Identity()\n          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act3): ReLU(inplace=True)\n        )\n      )\n      (layer2): Sequential(\n        (0): ResNestBottleneck(\n          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act1): ReLU(inplace=True)\n          (conv2): SplitAttn(\n            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n            (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act0): ReLU(inplace=True)\n            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act1): ReLU(inplace=True)\n            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n            (rsoftmax): RadixSoftmax()\n          )\n          (bn2): Identity()\n          (act2): Identity()\n          (avd_last): AvgPool2d(kernel_size=3, stride=2, padding=1)\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act3): ReLU(inplace=True)\n          (downsample): Sequential(\n            (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n            (1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (1): ResNestBottleneck(\n          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act1): ReLU(inplace=True)\n          (conv2): SplitAttn(\n            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n            (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act0): ReLU(inplace=True)\n            (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act1): ReLU(inplace=True)\n            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n            (rsoftmax): RadixSoftmax()\n          )\n          (bn2): Identity()\n          (act2): Identity()\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act3): ReLU(inplace=True)\n        )\n      )\n      (layer3): Sequential(\n        (0): ResNestBottleneck(\n          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act1): ReLU(inplace=True)\n          (conv2): SplitAttn(\n            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n            (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act0): ReLU(inplace=True)\n            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act1): ReLU(inplace=True)\n            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n            (rsoftmax): RadixSoftmax()\n          )\n          (bn2): Identity()\n          (act2): Identity()\n          (avd_last): AvgPool2d(kernel_size=3, stride=2, padding=1)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act3): ReLU(inplace=True)\n          (downsample): Sequential(\n            (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n            (1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (1): ResNestBottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act1): ReLU(inplace=True)\n          (conv2): SplitAttn(\n            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n            (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act0): ReLU(inplace=True)\n            (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act1): ReLU(inplace=True)\n            (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n            (rsoftmax): RadixSoftmax()\n          )\n          (bn2): Identity()\n          (act2): Identity()\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act3): ReLU(inplace=True)\n        )\n      )\n      (layer4): Sequential(\n        (0): ResNestBottleneck(\n          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act1): ReLU(inplace=True)\n          (conv2): SplitAttn(\n            (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n            (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act0): ReLU(inplace=True)\n            (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act1): ReLU(inplace=True)\n            (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n            (rsoftmax): RadixSoftmax()\n          )\n          (bn2): Identity()\n          (act2): Identity()\n          (avd_last): AvgPool2d(kernel_size=3, stride=2, padding=1)\n          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act3): ReLU(inplace=True)\n          (downsample): Sequential(\n            (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n            (1): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (1): ResNestBottleneck(\n          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act1): ReLU(inplace=True)\n          (conv2): SplitAttn(\n            (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n            (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act0): ReLU(inplace=True)\n            (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (act1): ReLU(inplace=True)\n            (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n            (rsoftmax): RadixSoftmax()\n          )\n          (bn2): Identity()\n          (act2): Identity()\n          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (act3): ReLU(inplace=True)\n        )\n      )\n    )\n    (decoder): LinknetDecoder(\n      (blocks): ModuleList(\n        (0): DecoderBlock(\n          (block): Sequential(\n            (0): Conv2dReLU(\n              (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): ReLU(inplace=True)\n            )\n            (1): TransposeX2(\n              (0): ConvTranspose2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): ReLU(inplace=True)\n            )\n            (2): Conv2dReLU(\n              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): ReLU(inplace=True)\n            )\n          )\n        )\n        (1): DecoderBlock(\n          (block): Sequential(\n            (0): Conv2dReLU(\n              (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): ReLU(inplace=True)\n            )\n            (1): TransposeX2(\n              (0): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): ReLU(inplace=True)\n            )\n            (2): Conv2dReLU(\n              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): ReLU(inplace=True)\n            )\n          )\n        )\n        (2): DecoderBlock(\n          (block): Sequential(\n            (0): Conv2dReLU(\n              (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): ReLU(inplace=True)\n            )\n            (1): TransposeX2(\n              (0): ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): ReLU(inplace=True)\n            )\n            (2): Conv2dReLU(\n              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): ReLU(inplace=True)\n            )\n          )\n        )\n        (3): DecoderBlock(\n          (block): Sequential(\n            (0): Conv2dReLU(\n              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): ReLU(inplace=True)\n            )\n            (1): TransposeX2(\n              (0): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): ReLU(inplace=True)\n            )\n            (2): Conv2dReLU(\n              (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): ReLU(inplace=True)\n            )\n          )\n        )\n        (4): DecoderBlock(\n          (block): Sequential(\n            (0): Conv2dReLU(\n              (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): ReLU(inplace=True)\n            )\n            (1): TransposeX2(\n              (0): ConvTranspose2d(16, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): ReLU(inplace=True)\n            )\n            (2): Conv2dReLU(\n              (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n              (2): ReLU(inplace=True)\n            )\n          )\n        )\n      )\n    )\n    (segmentation_head): SegmentationHead(\n      (0): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))\n      (1): Identity()\n      (2): Activation(\n        (activation): Identity()\n      )\n    )\n  )\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 33,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": true
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1670222048351
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lidar = load_lidar(lidarfilepath, (self.opts[\"imagesize\"], self.opts[\"imagesize\"]))"
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1670221619892
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "valloader = create_dataloader(opts, val_transforms, val_image_only_transforms, \"validation\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Reusing dataset mapai_training_data (/home/azureuser/.cache/huggingface/datasets/sjyhne___mapai_training_data/building_segmentation/1.0.0/b0b52f8c47ddbeae1962ab524cabb5fbed58d91cc70f9ac4c5981c071ad5f248)\n"
        }
      ],
      "execution_count": 22,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1670221744733
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out = model.eval()([:1].to(opts['device']).float())\r\n",
        "out.shape"
      ],
      "outputs": [],
      "execution_count": 43,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1670222121900
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        " calculate_score(output.detach().numpy().astype(np.uint8), label.detach().numpy().astype(np.uint8))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "plt.imshow(  out[0].detach().cpu().permute(1, 2, 0)[:,:,0]  )\r\n",
        "plt.show()\r\n",
        "plt.imshow(  out[0].detach().cpu().permute(1, 2, 0)[:,:,1]  )"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1670254632445
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RESIZE TO 500?"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lidar = load_lidar(\"../../data/train/lidar/6051_689_0.tif\", (512, 512))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/tmp/ipykernel_96048/4045903770.py:35: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  lidar = lidar.astype(np.float) / 255\n"
        }
      ],
      "execution_count": 32,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1670176069735
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Sat Dec  3 17:22:54 2022       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 470.141.03   Driver Version: 470.141.03   CUDA Version: 11.4     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|                               |                      |               MIG M. |\r\n|===============================+======================+======================|\r\n|   0  Tesla T4            On   | 00000001:00:00.0 Off |                  Off |\r\n| N/A   42C    P0    26W /  70W |  15160MiB / 16127MiB |      0%      Default |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                                  |\r\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n|        ID   ID                                                   Usage      |\r\n|=============================================================================|\r\n|    0   N/A  N/A     26467      C   ...s/azureml_py38/bin/python    15157MiB |\r\n+-----------------------------------------------------------------------------+\r\n"
        }
      ],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}